# -*- coding: utf-8 -*-
"""hackthon.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RhB3MPFvOpRYhU9GOxEOfyOOzQJu7bGD
"""

!pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain

pip install -U langsmith

import os
os.environ['LANGCHAIN_TRACING_V2'] = 'true'
os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'
os.environ['LANGCHAIN_API_KEY'] = "api key "

os.environ['OPENAI_API_KEY'] = "api key "

"""building code to exract code from pdf tables ."""

!pip install PyPDF2 langchain openai
!pip install tabula-py

import tabula
import pandas as pd
from typing import List, Tuple
all_tables = []
def extract_tables_from_pdf(file_path: str, pages: str = "all") -> Tuple[List[List[str]], List[pd.DataFrame]]:

    original_tables = tabula.read_pdf(file_path, pages=pages, multiple_tables=True)

    for table in original_tables:
        # Clean the table
        table.columns = table.columns.str.replace('\n', ' ').str.strip()
        table = table.applymap(lambda x: x.replace('\n', ' ') if isinstance(x, str) else x)

        # Convert DataFrame to list of lists
        table_list = table.values.tolist()
        table_list.insert(0, table.columns.tolist())  # Add headers as the first row
        all_tables.append(table_list)

    return all_tables, original_tables

# Example usage
file_path = '/content/y213hTgaho.pdf'
processed_tables, tables = extract_tables_from_pdf(file_path)

# Print the processed tables
for i, table in enumerate(processed_tables):
    print(f"Table {i + 1}:")
    for row in table:
        print(row)
    print("\n")

# all_tables
final_tables = []
for i in all_tables:
  for j in i:
      if (len(j) == 9) and (j not in final_tables):
        final_tables.append(j)
final_tables = pd.DataFrame(final_tables)
final_tables.to_csv("final_tables1.csv")

import tabula
import pandas as pd
from typing import List, Tuple

def extract_tables_from_pdf(file_path: str, pages: str = "all") -> Tuple[List[List[str]], List[pd.DataFrame]]:
    original_tables = tabula.read_pdf(file_path, pages=pages, multiple_tables=True)
    all_tables = []

    for table in original_tables:
        # Clean the table
        table.columns = table.columns.str.replace('\n', ' ').str.strip()
        table = table.applymap(lambda x: x.replace('\n', ' ') if isinstance(x, str) else x)

        # Convert DataFrame to list of lists
        table_list = table.values.tolist()
        table_list.insert(0, table.columns.tolist())  # Add headers as the first row
        all_tables.append(table_list)

    return all_tables, original_tables

def concatenate_tables(tables: List[List[List[str]]]) -> List[List[str]]:
    concatenated_table = []
    for table in tables:
        concatenated_table.extend(table)
    return concatenated_table

# Example usage
file_path = '/content/uqp8fkJo8p.pdf'
processed_tables, tables = extract_tables_from_pdf(file_path)

# Concatenate all tables
concatenated_table = concatenate_tables(processed_tables)

# Convert the concatenated table to a DataFrame
concatenated_df = pd.DataFrame(concatenated_table[1:], columns=concatenated_table[0])

# Save the concatenated table to a CSV file
concatenated_df.to_csv('concatenated_tables.csv', index=False)

# Print the concatenated DataFrame for verification
print(concatenated_df)

# Ensure you have the necessary packages installed
!pip install -U langchain-openai
!pip install langchain faiss-cpu
from langchain_openai import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.llms import OpenAI
from langchain_community.document_loaders.csv_loader import CSVLoader

# Load CSV data
loader = CSVLoader(file_path='/content/purchasedetails_tables.csv')
data = loader.load()
data

# Load CSV data
loader = CSVLoader(file_path='/content/second_tablecsv data .csv')
data1 = loader.load()
data1



from langchain_community.document_loaders.csv_loader import CSVLoader


loader = CSVLoader(file_path='/content/purchasedetails_tables.csv')
data = loader.load()
data

from langchain import hub
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.document_loaders.csv_loader import CSVLoader
from langchain_community.document_loaders.csv_loader import CSVLoader
from langchain_community.vectorstores import Chroma
from langchain_core.output_parsers import StrOutputParser
from langchain_core.runnables import RunnablePassthrough
from langchain_openai import ChatOpenAI, OpenAIEmbeddings

from langchain.text_splitter import RecursiveCharacterTextSplitter
text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
    chunk_size=15000)

# Make splits
splits = text_splitter.split_documents(data)

len(splits)

from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import Chroma
vectorstore = Chroma.from_documents(documents=splits,
                                    embedding=OpenAIEmbeddings())

retriever = vectorstore.as_retriever()
retriever

prompt = hub.pull("rlm/rag-prompt")
prompt
# LLM
llm = ChatOpenAI(model_name="gpt-3.5-turbo", temperature=0.57)

# Post-processing
def format_docs(docs):
    return "\n\n".join(doc.page_content for doc in docs)

# Chain
rag_chain = (
    {"context": retriever | format_docs, "question": RunnablePassthrough()}
    | prompt
    | llm
    | StrOutputParser()
)

# Question
rag_chain.invoke("What is the total bond amount enchased by TELUGU DESAM PARTY on 12th April 2019?")



rag_chain.invoke("What is the total amount received by AAM AADMI PARTY from DR. MANDEEP SHARMA in the year 2022?")